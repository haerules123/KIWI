import os
import sys
import gc
import json
import time
import ctypes
from tqdm import tqdm
import mysql.connector
import torch
import google.generativeai as genai
from dotenv import load_dotenv

from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from sentence_transformers import CrossEncoder

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ==============================================================================
# âš™ï¸ ì„¤ì •ê°’
# ==============================================================================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
PERSIST_DIRECTORY = "./chromadb_report"
EMBEDDING_MODEL = "BAAI/bge-m3"
RERANKER_MODEL_NAME = "dragonkue/bge-reranker-v2-m3-ko"
TARGET_GENRE = "ì—”í„°í…Œì¸ë¨¼íŠ¸"
MIN_CHUNKS_FOR_YEAR = 5  # ì—°ê°„ ë¦¬í¬íŠ¸ëŠ” ë°ì´í„°ê°€ ë” ë§ì´ í•„ìš”í•¨

DB_CONFIG = {
    'host': os.getenv('host'),
    'user': os.getenv('user'),
    'password': os.getenv('passwd'),
    'database': os.getenv('dbname'),
    'autocommit': False
}

# ë¶„ì„í•  ì—°ë„ ì„¤ì •
START_YEAR = 2023
END_YEAR = 2025  # 2026ë…„ì€ ì•„ì§ ëë‚˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ì œì™¸ ê¶Œì¥

# ì „ì—­ ë³€ìˆ˜
device = "cuda" if torch.cuda.is_available() else "cpu"
vector_store = None
reranker = None

# ==============================================================================
# ğŸ› ï¸ DB ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==============================================================================
def get_db_connection():
    try:
        return mysql.connector.connect(**DB_CONFIG)
    except Exception as e:
        print(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def close_db_safely(conn, cursor=None):
    try:
        if cursor: cursor.close()
        if conn and conn.is_connected(): conn.close()
    except: pass

def get_or_create_yearly_version(conn, app_id, year_str):
    """
    [L3 ì „ìš©] ì—°ë„(ì˜ˆ: '2024')ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê°€ìƒ ë²„ì „ì„ ìƒì„±/ì¡°íšŒ
    """
    cursor = conn.cursor(dictionary=True)
    try:
        # 1. ì¡°íšŒ
        check_sql = "SELECT v_idx FROM version WHERE a_idx = %s AND v_version = %s"
        cursor.execute(check_sql, (app_id, year_str))
        row = cursor.fetchone()
        
        if row:
            return row['v_idx']
        
        # 2. ìƒì„± (created_at ì—†ì´)
        insert_sql = "INSERT INTO version (a_idx, v_version) VALUES (%s, %s)"
        cursor.execute(insert_sql, (app_id, year_str))
        conn.commit()
        
        return cursor.lastrowid
        
    except mysql.connector.Error as e:
        if e.errno == 1062: # Duplicate entry
            cursor.execute(check_sql, (app_id, year_str))
            row = cursor.fetchone()
            if row: return row['v_idx']
        print(f"  âŒ ì—°ê°„ ë²„ì „ ìƒì„± ì‹¤íŒ¨: {e}")
        conn.rollback()
        return None
    finally:
        cursor.close()

def save_l3_report(app_id, year_str, report_text):
    """
    analytics í…Œì´ë¸”ì— L3 ë¦¬í¬íŠ¸ ì €ì¥
    """
    conn = get_db_connection()
    if not conn: return False
    
    try:
        # 1. ì—°ë„ìš© ê°€ìƒ ë²„ì „ ID (ì˜ˆ: '2024')
        v_idx = get_or_create_yearly_version(conn, app_id, year_str)
        if not v_idx:
            return False

        cursor = conn.cursor()
        
        # 2. ì €ì¥ (an_level='L3')
        query = """
            INSERT INTO analytics (v_idx, an_text, an_level, an_vectorized_at) 
            VALUES (%s, %s, 'L3', NULL)
            ON DUPLICATE KEY UPDATE 
                an_text = VALUES(an_text),
                an_vectorized_at = NULL
        """
        cursor.execute(query, (v_idx, report_text))
        conn.commit()
        return True
        
    except Exception as e:
        print(f"  âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
        conn.rollback()
        return False
    finally:
        close_db_safely(conn)

def get_target_apps(genre):
    conn = get_db_connection()
    if not conn: return []
    try:
        cursor = conn.cursor(dictionary=True)
        sql = """
            SELECT a.a_idx, a.a_name 
            FROM app a
            JOIN app_genre ag ON a.ag_idx = ag.ag_idx
            WHERE ag.ag_name = %s
        """
        cursor.execute(sql, (genre,))
        return cursor.fetchall()
    finally:
        close_db_safely(conn)

# ==============================================================================
# ğŸ” RAG ë° LLM ë¡œì§ (Yearly)
# ==============================================================================
def aggressive_gc():
    gc.collect()
    if device == "cuda":
        torch.cuda.empty_cache()
    try:
        ctypes.CDLL("libc.so.6").malloc_trim(0)
    except:
        pass

def get_yearly_context(app_name, year_int, vector_store, reranker, top_k=30):
    """
    í•´ë‹¹ ì—°ë„(year_int)ì˜ ëª¨ë“  L1 ë°ì´í„°ë¥¼ ê²€ìƒ‰
    """
    # 1. ê²€ìƒ‰ì–´: ì—°ê°„ íë¦„ íŒŒì•…ì„ ìœ„í•œ ê´‘ë²”ìœ„í•œ ì¿¼ë¦¬
    search_queries = [
        f"{app_name} {year_int}ë…„ ì£¼ìš” ì—…ë°ì´íŠ¸ ë° ì´ìŠˆ",
        f"{app_name} {year_int}ë…„ ì‚¬ìš©ì í”¼ë“œë°± ì¢…í•©",
        f"{app_name} {year_int}ë…„ ê¸ì • ë¶€ì • í‰ê°€"
    ]
    
    # 2. ë©”íƒ€ë°ì´í„° í•„í„° (Ingest ì‹œ yearë¥¼ intë¡œ ë„£ì—ˆìŒ)
    search_filter = {
        "$and": [
            {"app_name": app_name},
            {"year": year_int}
        ]
    }
    
    unique_contents = set()
    all_docs = []
    
    # 3. ê²€ìƒ‰
    for query in search_queries:
        try:
            results = vector_store.similarity_search(
                query=query,
                k=top_k,
                filter=search_filter
            )
            for doc in results:
                if doc.page_content not in unique_contents:
                    unique_contents.add(doc.page_content)
                    all_docs.append(doc)
        except Exception:
            continue

    if not all_docs:
        return [], set()

    # 4. Reranking
    doc_texts = [d.page_content for d in all_docs]
    rerank_query = f"{app_name} {year_int}ë…„ ì„±ê³¼ ë¶„ì„"
    pairs = [[rerank_query, text] for text in doc_texts]
    
    try:
        scores = reranker.predict(pairs, batch_size=4, show_progress_bar=False) if reranker else [0.0] * len(pairs)
    except:
        scores = [0.0] * len(pairs)

    scored_docs = sorted(list(zip(all_docs, scores)), key=lambda x: x[1], reverse=True)
    
    final_context = []
    detected_quarters = set()
    
    # ìƒìœ„ 30ê°œ ì‚¬ìš©
    for doc, score in scored_docs[:30]:
        q_id = doc.metadata.get('quarter_id', 'Unknown') # ë¶„ê¸° ì •ë³´ë„ ê°™ì´ ìˆ˜ì§‘
        if q_id != 'Unknown':
            detected_quarters.add(q_id)
            
        final_context.append({
            "text": doc.page_content,
            "quarter": q_id,
            "version": doc.metadata.get('version', 'Unknown'),
            "keywords": doc.metadata.get('keywords', ''),
            "sentiment": doc.metadata.get('sentiment', '')
        })
        
    return final_context, detected_quarters

def generate_l3_report(app_name, year_str, context_data, detected_quarters):
    if not context_data:
        return None

    quarters_str = ", ".join(sorted(list(detected_quarters)))
    context_json = json.dumps(context_data, ensure_ascii=False, indent=2)

    prompt = f"""
ë‹¹ì‹ ì€ ëª¨ë°”ì¼ ì•± ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ë°ì´í„°ëŠ” **[{app_name}]**ì˜ **[{year_str}ë…„]** ì „ì²´ ê¸°ê°„ ë™ì•ˆ ìˆ˜ì§‘ëœ L1(ë²„ì „ë³„) ë¦¬í¬íŠ¸ë“¤ì˜ í•µì‹¬ ë‚´ìš©ì…ë‹ˆë‹¤.
ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì—°ê°„ ê²°ì‚°(L3) ë³´ê³ ì„œ**ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

ğŸ›‘ [í•„ìˆ˜ ì œì•½ ì‚¬í•­]
1. ë³´ê³ ì„œ ì œëª©: **"{app_name} {year_str}ë…„ ì—°ê°„ ì¢…í•© ë³´ê³ ì„œ"**
2. **ë¶„ì„ ëŒ€ìƒ ë¶„ê¸°({quarters_str})**ë¥¼ ê°œìš”ì— ëª…ì‹œí•˜ì‹­ì‹œì˜¤.
3. ë‹¨ìˆœ ë‚˜ì—´ì´ ì•„ë‹Œ, 1ë…„ ë™ì•ˆì˜ **íë¦„(Trend)ê³¼ ë³€í™”**ì— ì§‘ì¤‘í•˜ì‹­ì‹œì˜¤.
4. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.

[Context Data]
{context_json}

[ë³´ê³ ì„œ ì–‘ì‹]
# {app_name} {year_str}ë…„ ì—°ê°„ ì¢…í•© ë³´ê³ ì„œ

## 1. ğŸ“‘ ì—°ê°„ ê°œìš” (Executive Summary)
*   **ë¶„ì„ ì—°ë„**: {year_str}ë…„
*   **í¬í•¨ëœ ë¶„ê¸°**: {quarters_str}
*   **ì¢…í•© í‰ê°€**: (1ë…„ ê°„ì˜ ì„±ì¥ì„ í‰ê°€í•˜ëŠ” 3~4ë¬¸ì¥ ìš”ì•½)

## 2. ğŸ“ˆ ì—°ê°„ ì£¼ìš” ë³€í™” íë¦„ (Yearly Trend)
(ì‹œê°„ íë¦„ì— ë”°ë¥¸ ê¸/ë¶€ì • ì´ìŠˆì˜ ë³€í™” ì–‘ìƒ ì„œìˆ )
*   **ìƒë°˜ê¸°**: ...
*   **í•˜ë°˜ê¸°**: ...

## 3. ğŸš¨ í•µì‹¬ ì´ìŠˆ íšŒê³  (Critical Issues)
(í•œ í•´ ë™ì•ˆ ê°€ì¥ ì¹˜ëª…ì ì´ì—ˆê±°ë‚˜ ë°˜ë³µëœ ë¬¸ì œì )
*   **Top 1**: ...
*   **Top 2**: ...

## 4. ğŸ† ì˜¬í•´ì˜ ì„±ê³¼ (Achievements)
(ì‚¬ìš©ìë“¤ì—ê²Œ ê°€ì¥ ì‚¬ë‘ë°›ì€ ê¸°ëŠ¥ì´ë‚˜ ì„±ê³µì ì¸ ì—…ë°ì´íŠ¸)
*   ...

## 5. ğŸ”­ ë‚´ë…„ë„ ì „ëµ ì œì–¸ (Next Year Strategy)
(ì˜¬í•´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‚´ë…„ì— ì§‘ì¤‘í•´ì•¼ í•  í•µì‹¬ ë¶„ì•¼ ì œì•ˆ)
*   ...
"""
    try:
        model = genai.GenerativeModel('gemini-2.0-flash')
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(temperature=0.2)
        )
        return response.text
    except Exception as e:
        print(f"âŒ LLM ìƒì„± ì—ëŸ¬: {e}")
        return None

# ==============================================================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰
# ==============================================================================
def main():
    global vector_store, reranker
    
    genai.configure(api_key=GEMINI_API_KEY)
    
    print("ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘...", end=" ")
    embeddings = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL,
        model_kwargs={'device': device},
        encode_kwargs={'normalize_embeddings': True}
    )
    
    vector_store = Chroma(
        persist_directory=PERSIST_DIRECTORY,
        embedding_function=embeddings
    )
    
    try:
        reranker = CrossEncoder(RERANKER_MODEL_NAME, device=device, max_length=1024)
    except:
        reranker = None
    print("ì™„ë£Œ")

    target_apps = get_target_apps(TARGET_GENRE)
    target_years = [str(y) for y in range(START_YEAR, END_YEAR + 1)]
    
    print(f"ğŸ“Š ëŒ€ìƒ ì•±: {len(target_apps)}ê°œ")
    print(f"ğŸ“… ëŒ€ìƒ ì—°ë„: {target_years}")

    for app in tqdm(target_apps, desc="App Loop"):
        app_name = app['a_name']
        app_id = app['a_idx']
        
        print(f"\nğŸ“± [{app_name}] L3 ë¶„ì„ ì‹œì‘")
        
        for year_str in target_years:
            aggressive_gc()
            year_int = int(year_str)
            
            # 1. RAG ê²€ìƒ‰ (Year Filter)
            context, quarters = get_yearly_context(
                app_name, year_int, vector_store, reranker
            )
            
            if len(context) < MIN_CHUNKS_FOR_YEAR:
                # print(f"  â­ï¸ {year_str}: ë°ì´í„° ë¶€ì¡± ({len(context)} chunks)")
                continue
                
            print(f"  ğŸ” {year_str}: {len(context)}ê°œ ì²­í¬ í™•ë³´ ({len(quarters)}ê°œ ë¶„ê¸° ë°ì´í„°)")
            
            # 2. LLM ìƒì„±
            report_text = generate_l3_report(app_name, year_str, context, quarters)
            
            if report_text:
                # 3. DB ì €ì¥ (L3)
                if save_l3_report(app_id, year_str, report_text):
                    print(f"    âœ… L3 ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ")
                else:
                    print(f"    âŒ ì €ì¥ ì‹¤íŒ¨")
            else:
                print(f"    âš ï¸ ìƒì„± ì‹¤íŒ¨")
                
            time.sleep(1)

    print("\nğŸ‰ L3 ì—°ê°„ ë¶„ì„ ì™„ë£Œ!")

if __name__ == "__main__":
    main()