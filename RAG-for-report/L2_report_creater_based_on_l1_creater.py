import os
import sys
import gc
import json
import time
import ctypes
from tqdm import tqdm
import mysql.connector
import torch
import google.generativeai as genai
from dotenv import load_dotenv

from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from sentence_transformers import CrossEncoder

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ==============================================================================
# âš™ï¸ ì„¤ì •ê°’
# ==============================================================================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
PERSIST_DIRECTORY = "./chromadb_report"
EMBEDDING_MODEL = "BAAI/bge-m3"
RERANKER_MODEL_NAME = "dragonkue/bge-reranker-v2-m3-ko"
TARGET_GENRE = "ì—”í„°í…Œì¸ë¨¼íŠ¸"
MIN_CHUNKS_FOR_QUARTER = 3

DB_CONFIG = {
    'host': os.getenv('host'),
    'user': os.getenv('user'),
    'password': os.getenv('passwd'),
    'database': os.getenv('dbname'),
    'autocommit': False
}

# ë¶„ì„í•  ê¸°ê°„ ì„¤ì •
START_YEAR = 2023
END_YEAR = 2026
END_QUARTER = 1

# ì „ì—­ ë³€ìˆ˜
device = "cuda" if torch.cuda.is_available() else "cpu"
vector_store = None
reranker = None

# ==============================================================================
# ğŸ› ï¸ DB ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==============================================================================
def get_db_connection():
    try:
        return mysql.connector.connect(**DB_CONFIG)
    except Exception as e:
        print(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def close_db_safely(conn, cursor=None):
    try:
        if cursor: cursor.close()
        if conn and conn.is_connected(): conn.close()
    except: pass

def get_or_create_quarter_version(conn, app_id, quarter_id):
    """
    [ìˆ˜ì •ë¨] version í…Œì´ë¸” ìŠ¤í‚¤ë§ˆì— ë§ì¶° created_at ì œê±°
    (v_idx, v_version, a_idx) ë§Œ ì¡´ì¬í•¨
    """
    cursor = conn.cursor(dictionary=True)
    try:
        # 1. í•´ë‹¹ ë¶„ê¸° ë²„ì „ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
        check_sql = "SELECT v_idx FROM version WHERE a_idx = %s AND v_version = %s"
        cursor.execute(check_sql, (app_id, quarter_id))
        row = cursor.fetchone()
        
        if row:
            return row['v_idx']
        
        # 2. ì—†ë‹¤ë©´ ìƒì„± (created_at ì œì™¸)
        insert_sql = "INSERT INTO version (a_idx, v_version) VALUES (%s, %s)"
        cursor.execute(insert_sql, (app_id, quarter_id))
        conn.commit()
        
        return cursor.lastrowid
        
    except mysql.connector.Error as e:
        # ë™ì‹œì„± ë¬¸ì œë¡œ ì´ë¯¸ ì¡´ì¬í•  ê²½ìš° ì¬ì¡°íšŒ
        if e.errno == 1062: # Duplicate entry
            cursor.execute(check_sql, (app_id, quarter_id))
            row = cursor.fetchone()
            if row: return row['v_idx']
            
        print(f"  âŒ ë²„ì „ ìƒì„± ì‹¤íŒ¨: {e}")
        conn.rollback()
        return None
    finally:
        cursor.close()

def save_l2_report(app_id, quarter_id, report_text):
    """
    analytics í…Œì´ë¸”ì— L2 ë¦¬í¬íŠ¸ ì €ì¥
    """
    conn = get_db_connection()
    if not conn: return False
    
    try:
        # 1. ë¶„ê¸°ìš© ê°€ìƒ ë²„ì „ ID ê°€ì ¸ì˜¤ê¸°
        v_idx = get_or_create_quarter_version(conn, app_id, quarter_id)
        if not v_idx:
            print(f"    âŒ ê°€ìƒ ë²„ì „ ìƒì„± ì‹¤íŒ¨: {quarter_id}")
            return False

        cursor = conn.cursor()
        
        # 2. INSERT ... ON DUPLICATE KEY UPDATE
        # v_idx + an_level ì¡°í•©ì´ Unique Key (uk_version_level)
        query = """
            INSERT INTO analytics (v_idx, an_text, an_level, an_vectorized_at) 
            VALUES (%s, %s, 'L2', NULL)
            ON DUPLICATE KEY UPDATE 
                an_text = VALUES(an_text),
                an_vectorized_at = NULL
        """
        cursor.execute(query, (v_idx, report_text))
        conn.commit()
        return True
        
    except Exception as e:
        print(f"  âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
        conn.rollback()
        return False
    finally:
        close_db_safely(conn)

def get_target_apps(genre):
    conn = get_db_connection()
    if not conn: return []
    try:
        cursor = conn.cursor(dictionary=True)
        sql = """
            SELECT a.a_idx, a.a_name 
            FROM app a
            JOIN app_genre ag ON a.ag_idx = ag.ag_idx
            WHERE ag.ag_name = %s
        """
        cursor.execute(sql, (genre,))
        return cursor.fetchall()
    finally:
        close_db_safely(conn)

# ==============================================================================
# ğŸ” RAG ë° LLM ë¡œì§
# ==============================================================================
def get_target_quarters():
    quarters = []
    for year in range(START_YEAR, END_YEAR + 1):
        for q in range(1, 5):
            if year == END_YEAR and q > END_QUARTER:
                break
            quarters.append(f"{year}-Q{q}")
    return quarters

def aggressive_gc():
    gc.collect()
    if device == "cuda":
        torch.cuda.empty_cache()
    try:
        ctypes.CDLL("libc.so.6").malloc_trim(0)
    except:
        pass

def get_quarter_context(app_name, quarter_id, vector_store, reranker, top_k=20):
    search_queries = [
        f"{app_name} {quarter_id} ì£¼ìš” ì´ìŠˆ ë° ë¬¸ì œì ",
        f"{app_name} {quarter_id} ì‚¬ìš©ì ê¸ì • ë°˜ì‘",
        f"{app_name} {quarter_id} ì—…ë°ì´íŠ¸ ë°˜ì‘ ê¸°ëŠ¥"
    ]
    
    search_filter = {
        "$and": [
            {"app_name": app_name},
            {"quarter_id": quarter_id}
        ]
    }
    
    unique_contents = set()
    all_docs = []
    
    for query in search_queries:
        try:
            results = vector_store.similarity_search(
                query=query,
                k=top_k,
                filter=search_filter
            )
            for doc in results:
                if doc.page_content not in unique_contents:
                    unique_contents.add(doc.page_content)
                    all_docs.append(doc)
        except Exception:
            continue

    if not all_docs:
        return [], set()

    doc_texts = [d.page_content for d in all_docs]
    rerank_query = f"{app_name} {quarter_id} ì¢…í•© ë¶„ì„"
    pairs = [[rerank_query, text] for text in doc_texts]
    
    try:
        scores = reranker.predict(pairs, batch_size=4, show_progress_bar=False) if reranker else [0.0] * len(pairs)
    except:
        scores = [0.0] * len(pairs)

    scored_docs = sorted(list(zip(all_docs, scores)), key=lambda x: x[1], reverse=True)
    
    final_context = []
    detected_versions = set()
    
    for doc, score in scored_docs[:25]:
        ver = doc.metadata.get('version', 'Unknown')
        if ver != 'Unknown':
            detected_versions.add(ver)
            
        final_context.append({
            "text": doc.page_content,
            "version": ver,
            "keywords": doc.metadata.get('keywords', ''),
            "sentiment": doc.metadata.get('sentiment', '')
        })
        
    return final_context, detected_versions

def generate_l2_report(app_name, quarter_id, context_data, detected_versions):
    if not context_data:
        return None

    versions_str = ", ".join(sorted(list(detected_versions)))
    context_json = json.dumps(context_data, ensure_ascii=False, indent=2)
    year, q = quarter_id.split('-')
    quarter_title = f"{year}ë…„ {q[1]}ë¶„ê¸°"

    prompt = f"""
ë‹¹ì‹ ì€ ëª¨ë°”ì¼ ì•± ì„œë¹„ìŠ¤ ì´ê´„ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ì œê³µëœ ë°ì´í„°ëŠ” **[{app_name}]**ì˜ **[{quarter_title}]** ê¸°ê°„ ë™ì•ˆ ë°œí–‰ëœ ìƒì„¸ ë¦¬í¬íŠ¸(L1)ë“¤ì˜ í•µì‹¬ ë‚´ìš©ì…ë‹ˆë‹¤.
ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ ë¶„ê¸°ì˜ ì„±ê³¼ë¥¼ ê²°ì‚°í•˜ëŠ” ë³´ê³ ì„œ(L2)ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

ğŸ›‘ [í•„ìˆ˜ ì œì•½ ì‚¬í•­]
1. ë³´ê³ ì„œ ì œëª©ì€ **"{app_name} {quarter_title} ê²°ì‚° ë³´ê³ ì„œ"**ì—¬ì•¼ í•©ë‹ˆë‹¤.
2. **ì°¸ì¡°ëœ ë²„ì „({versions_str})**ì„ ê°œìš”ì— ëª…ì‹œí•˜ì‹­ì‹œì˜¤.
3. ì—†ëŠ” ì‚¬ì‹¤ì„ ì§€ì–´ë‚´ì§€ ë§ê³ , ì œê³µëœ Context ë°ì´í„°ì— ê¸°ë°˜í•˜ì—¬ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
4. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.

[Context Data]
{context_json}

[ë³´ê³ ì„œ ì–‘ì‹]
# {app_name} {quarter_title} ê²°ì‚° ë³´ê³ ì„œ

## 1. ğŸ“‘ ê°œìš”
*   **ë¶„ì„ ê¸°ê°„**: {quarter_title}
*   **ì°¸ì¡° ë²„ì „**: {versions_str}
*   **ë¶„ê¸° ìš”ì•½**: (ì „ì²´ì ì¸ ë¶„ìœ„ê¸°ì™€ í•µì‹¬ ì´ìŠˆ 1ì¤„ ìš”ì•½)

## 2. ğŸ“Š ë¶„ê¸° í•µì‹¬ ì´ìŠˆ (Key Issues)
(ê°€ì¥ ë¹ˆë²ˆí•˜ê±°ë‚˜ ì‹¬ê°í–ˆë˜ ë¬¸ì œì  ìœ„ì£¼)
*   **ì´ìŠˆ 1**: ...
*   **ì´ìŠˆ 2**: ...

## 3. ğŸ† ì£¼ìš” ê¸ì • ë°˜ì‘ (Highlights)
(ì‚¬ìš©ì í˜¸í‰ ìš”ì†Œ)
*   ...

## 4. ğŸš€ ì°¨ê¸° ë¶„ê¸° ì œì–¸
(L1 ë¦¬í¬íŠ¸ë“¤ì„ ì¢…í•©í–ˆì„ ë•Œ í•„ìš”í•œ ê°œì„  ë°©í–¥)
*   ...
"""
    try:
        model = genai.GenerativeModel('gemini-2.0-flash')
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(temperature=0.2)
        )
        return response.text
    except Exception as e:
        print(f"âŒ LLM ìƒì„± ì—ëŸ¬: {e}")
        return None

# ==============================================================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰
# ==============================================================================
def main():
    global vector_store, reranker
    
    genai.configure(api_key=GEMINI_API_KEY)
    
    print("ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘...", end=" ")
    embeddings = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL,
        model_kwargs={'device': device},
        encode_kwargs={'normalize_embeddings': True}
    )
    
    vector_store = Chroma(
        persist_directory=PERSIST_DIRECTORY,
        embedding_function=embeddings
    )
    
    try:
        reranker = CrossEncoder(RERANKER_MODEL_NAME, device=device, max_length=512)
    except:
        reranker = None
    print("ì™„ë£Œ")

    target_apps = get_target_apps(TARGET_GENRE)
    target_quarters = get_target_quarters()
    
    print(f"ğŸ“Š ëŒ€ìƒ ì•±: {len(target_apps)}ê°œ")
    print(f"ğŸ“… ëŒ€ìƒ ê¸°ê°„: {target_quarters[0]} ~ {target_quarters[-1]}")

    for app in tqdm(target_apps, desc="App Loop"):
        app_name = app['a_name']
        app_id = app['a_idx']
        
        print(f"\nğŸ“± [{app_name}] ë¶„ì„ ì‹œì‘")
        
        for quarter_id in target_quarters:
            aggressive_gc()
            
            # 1. RAG ê²€ìƒ‰
            context, versions = get_quarter_context(
                app_name, quarter_id, vector_store, reranker
            )
            
            if len(context) < MIN_CHUNKS_FOR_QUARTER:
                continue
                
            print(f"  ğŸ” {quarter_id}: {len(context)}ê°œ ì²­í¬ í™•ë³´ (v{len(versions)}ê°œ ë²„ì „ ì°¸ì¡°)")
            
            # 2. LLM ë¦¬í¬íŠ¸ ìƒì„±
            report_text = generate_l2_report(app_name, quarter_id, context, versions)
            
            if report_text:
                # 3. DB ì €ì¥ (L2, ê°€ìƒ ë²„ì „ ìƒì„± í¬í•¨)
                if save_l2_report(app_id, quarter_id, report_text):
                    print(f"    âœ… ì €ì¥ ì™„ë£Œ")
                else:
                    print(f"    âŒ ì €ì¥ ì‹¤íŒ¨")
            else:
                print(f"    âš ï¸ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨")
                
            time.sleep(1)

    print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")

if __name__ == "__main__":
    main()