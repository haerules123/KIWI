import os
import sys
import gc
import json
import time
import ctypes
from tqdm import tqdm
import mysql.connector
import torch
import google.generativeai as genai
from dotenv import load_dotenv

from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from sentence_transformers import CrossEncoder

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ==============================================================================
# âš™ï¸ ì„¤ì •ê°’
# ==============================================================================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
PERSIST_DIRECTORY = "./chromadb_report"
EMBEDDING_MODEL = "BAAI/bge-m3"
RERANKER_MODEL_NAME = "dragonkue/bge-reranker-v2-m3-ko"
TARGET_GENRE = "ì—”í„°í…Œì¸ë¨¼íŠ¸"
MIN_CHUNKS_FOR_TOTAL = 10  # ì „ì²´ ë¶„ì„ì´ë¯€ë¡œ ë°ì´í„°ê°€ ë” ë§ì´ í•„ìš”í•¨

DB_CONFIG = {
    'host': os.getenv('host'),
    'user': os.getenv('user'),
    'password': os.getenv('passwd'),
    'database': os.getenv('dbname'),
    'autocommit': False
}

# ì „ì—­ ë³€ìˆ˜
device = "cuda" if torch.cuda.is_available() else "cpu"
vector_store = None
reranker = None

# ==============================================================================
# ğŸ› ï¸ DB ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==============================================================================
def get_db_connection():
    try:
        return mysql.connector.connect(**DB_CONFIG)
    except Exception as e:
        print(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def close_db_safely(conn, cursor=None):
    try:
        if cursor: cursor.close()
        if conn and conn.is_connected(): conn.close()
    except: pass

def get_or_create_total_version(conn, app_id):
    """
    [L4 ì „ìš©] ì„œë¹„ìŠ¤ ì „ì²´ë¥¼ ì˜ë¯¸í•˜ëŠ” 'TOTAL' ê°€ìƒ ë²„ì „ ìƒì„±/ì¡°íšŒ
    (created_at ì»¬ëŸ¼ ì‚¬ìš© ì•ˆ í•¨)
    """
    version_name = "TOTAL"
    cursor = conn.cursor(dictionary=True)
    try:
        # 1. ì¡°íšŒ
        check_sql = "SELECT v_idx FROM version WHERE a_idx = %s AND v_version = %s"
        cursor.execute(check_sql, (app_id, version_name))
        row = cursor.fetchone()
        
        if row:
            return row['v_idx']
        
        # 2. ìƒì„±
        insert_sql = "INSERT INTO version (a_idx, v_version) VALUES (%s, %s)"
        cursor.execute(insert_sql, (app_id, version_name))
        conn.commit()
        
        return cursor.lastrowid
        
    except mysql.connector.Error as e:
        if e.errno == 1062: # Duplicate entry
            cursor.execute(check_sql, (app_id, version_name))
            row = cursor.fetchone()
            if row: return row['v_idx']
        print(f"  âŒ Total ë²„ì „ ìƒì„± ì‹¤íŒ¨: {e}")
        conn.rollback()
        return None
    finally:
        cursor.close()

def save_l4_report(app_id, report_text):
    """
    analytics í…Œì´ë¸”ì— L4 ë¦¬í¬íŠ¸ ì €ì¥
    """
    conn = get_db_connection()
    if not conn: return False
    
    try:
        # 1. TOTAL ê°€ìƒ ë²„ì „ ID ì¡°íšŒ/ìƒì„±
        v_idx = get_or_create_total_version(conn, app_id)
        if not v_idx:
            return False

        cursor = conn.cursor()
        
        # 2. ì €ì¥ (an_level='L4')
        query = """
            INSERT INTO analytics (v_idx, an_text, an_level, an_vectorized_at) 
            VALUES (%s, %s, 'L4', NULL)
            ON DUPLICATE KEY UPDATE 
                an_text = VALUES(an_text),
                an_vectorized_at = NULL
        """
        cursor.execute(query, (v_idx, report_text))
        conn.commit()
        return True
        
    except Exception as e:
        print(f"  âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
        conn.rollback()
        return False
    finally:
        close_db_safely(conn)

def get_target_apps(genre):
    conn = get_db_connection()
    if not conn: return []
    try:
        cursor = conn.cursor(dictionary=True)
        sql = """
            SELECT a.a_idx, a.a_name 
            FROM app a
            JOIN app_genre ag ON a.ag_idx = ag.ag_idx
            WHERE ag.ag_name = %s
        """
        cursor.execute(sql, (genre,))
        return cursor.fetchall()
    finally:
        close_db_safely(conn)

# ==============================================================================
# ğŸ” RAG ë° LLM ë¡œì§ (All-Time / L4)
# ==============================================================================
def aggressive_gc():
    gc.collect()
    if device == "cuda":
        torch.cuda.empty_cache()
    try:
        ctypes.CDLL("libc.so.6").malloc_trim(0)
    except:
        pass

def get_total_context(app_name, vector_store, reranker, top_k=40):
    """
    [L4] ì‹œê°„ í•„í„° ì—†ì´ ì „ì²´ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì•±ì˜ 'ì—­ì‚¬'ì™€ 'ì •ì²´ì„±'ì„ íŒŒì•…
    """
    # 1. ê²€ìƒ‰ì–´: ê³¼ê±°ë¶€í„° í˜„ì¬ê¹Œì§€ë¥¼ ì•„ìš°ë¥´ëŠ” í¬ê´„ì  ì¿¼ë¦¬
    search_queries = [
        f"{app_name} ì„œë¹„ìŠ¤ ì—­ì‚¬ ë° ì£¼ìš” ë³€í™”",
        f"{app_name} ê³ ì§ˆì ì¸ ë¬¸ì œì ê³¼ í•´ê²° ê³¼ì •",
        f"{app_name} ì‚¬ìš©ìê°€ ê¼½ëŠ” ìµœê³ ì˜ ê¸°ëŠ¥ ì¥ì ",
        f"{app_name} ì—…ë°ì´íŠ¸ ì—°í˜ ë° í‰ê°€"
    ]
    
    # 2. ë©”íƒ€ë°ì´í„° í•„í„°: ì˜¤ì§ ì•± ì´ë¦„ë§Œ! (ë‚ ì§œ ì œí•œ ì—†ìŒ)
    search_filter = {"app_name": app_name}
    
    unique_contents = set()
    all_docs = []
    
    # 3. ê²€ìƒ‰
    for query in search_queries:
        try:
            results = vector_store.similarity_search(
                query=query,
                k=top_k,
                filter=search_filter
            )
            for doc in results:
                if doc.page_content not in unique_contents:
                    unique_contents.add(doc.page_content)
                    all_docs.append(doc)
        except Exception:
            continue

    if not all_docs:
        return [], set(), set()

    # 4. Reranking
    doc_texts = [d.page_content for d in all_docs]
    rerank_query = f"{app_name} ì„œë¹„ìŠ¤ ì¢…í•© í‰ê°€ ë° ì—­ì‚¬"
    pairs = [[rerank_query, text] for text in doc_texts]
    
    try:
        # L4ëŠ” ë°ì´í„°ê°€ ë§ì„ ìˆ˜ ìˆìœ¼ë‹ˆ ë°°ì¹˜ ì‚¬ì´ì¦ˆë‚˜ max_length ì¡°ì ˆ ì£¼ì˜
        scores = reranker.predict(pairs, batch_size=4, show_progress_bar=False) if reranker else [0.0] * len(pairs)
    except:
        scores = [0.0] * len(pairs)

    scored_docs = sorted(list(zip(all_docs, scores)), key=lambda x: x[1], reverse=True)
    
    final_context = []
    detected_years = set()
    detected_versions = set()
    
    # ìƒìœ„ 40ê°œ ì‚¬ìš© (ë°©ëŒ€í•œ ì–‘ì„ ì••ì¶•í•˜ê¸° ìœ„í•´ top_kë¥¼ ëŠ˜ë¦¼)
    for doc, score in scored_docs[:40]:
        # ì—°ë„ ìˆ˜ì§‘
        y = doc.metadata.get('year', 0)
        if y > 2000: detected_years.add(y)
        
        # ë²„ì „ ìˆ˜ì§‘
        v = doc.metadata.get('version', 'Unknown')
        if v != 'Unknown': detected_versions.add(v)
            
        final_context.append({
            "text": doc.page_content,
            "date": doc.metadata.get('date', 'Unknown'),
            "version": v,
            "year": y
        })
        
    return final_context, detected_years, detected_versions

def generate_l4_report(app_name, context_data, detected_years):
    if not context_data:
        return None

    # ë¶„ì„ ê¸°ê°„ íŒŒì•… (ì˜ˆ: 2023 ~ 2025)
    if detected_years:
        min_year = min(detected_years)
        max_year = max(detected_years)
        period_str = f"{min_year}ë…„ ~ {max_year}ë…„"
    else:
        period_str = "ì „ì²´ ê¸°ê°„"

    context_json = json.dumps(context_data, ensure_ascii=False, indent=2)

    prompt = f"""
ë‹¹ì‹ ì€ IT ì„œë¹„ìŠ¤ ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì´ì CIO(Chief Information Officer)ì…ë‹ˆë‹¤.
ì•„ë˜ ë°ì´í„°ëŠ” ëª¨ë°”ì¼ ì•± **[{app_name}]**ì˜ **ì„œë¹„ìŠ¤ ëŸ°ì¹­ ì´í›„ ì¶•ì ëœ ì „ì²´ íˆìŠ¤í† ë¦¬ ë°ì´í„°({period_str})**ì…ë‹ˆë‹¤.
ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì„œë¹„ìŠ¤ ì¢…í•© ì§„ë‹¨ ë³´ê³ ì„œ(L4)**ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

ğŸ›‘ [ì‘ì„± ì›ì¹™]
1. ë‹¨ìˆœí•œ ë²„ê·¸ ë‚˜ì—´ì´ ì•„ë‹Œ, **ì„œë¹„ìŠ¤ì˜ 'ì •ì²´ì„±(Identity)', 'ì„±ì¥ ê³¼ì •', 'ì‹œì¥ ë‚´ ìœ„ìƒ'**ì„ ë…¼í•˜ì‹­ì‹œì˜¤.
2. ë¶„ì„ ê¸°ê°„: **{period_str}**
3. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì „ë¬¸ì ìœ¼ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

[Context Data]
{context_json}

[ë³´ê³ ì„œ ì–‘ì‹]
# {app_name} ì„œë¹„ìŠ¤ ì¢…í•© ì§„ë‹¨ ë³´ê³ ì„œ

## 1. ğŸ›ï¸ ì„œë¹„ìŠ¤ ì˜¤ë²„ë·° (Executive Summary)
*   **ë¶„ì„ ë²”ìœ„**: {period_str}
*   **ì„œë¹„ìŠ¤ ì •ì²´ì„±**: (ì´ ì•±ì€ ì‚¬ìš©ìë“¤ì—ê²Œ ì–´ë–¤ ê°€ì¹˜ë¥¼ ì œê³µí•˜ëŠ”ê°€?)
*   **ì¢…í•© í‰ì **: (ë¦¬ë·° ë¶„ìœ„ê¸°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì •ì„±ì  í‰ê°€, ì˜ˆ: ìµœìƒ/ìš°ìˆ˜/ë³´í†µ/ë¯¸í¡)

## 2. ğŸ“œ ì„œë¹„ìŠ¤ ì§„í™”ì˜ ì—­ì‚¬ (History & Evolution)
(ì‹œê°„ íë¦„ì— ë”°ë¼ ì„œë¹„ìŠ¤ê°€ ì–´ë–»ê²Œ ë³€í™”í•˜ê³  ë°œì „í•´ì™”ëŠ”ì§€ ì„œìˆ )
*   **ì´ˆê¸°/ê³¼ê±°**: ...
*   **ìµœê·¼ ë™í–¥**: ...

## 3. ğŸ’ í•µì‹¬ ê°€ì¹˜ ë° ê°•ì  (Core Competencies)
(ì˜¤ëœ ê¸°ê°„ ë³€ì¹˜ ì•Šê³  ì‚¬ë‘ë°›ì€ ì´ ì•±ë§Œì˜ ê°•ë ¥í•œ ë¬´ê¸°)
*   **Strength 1**: ...
*   **Strength 2**: ...

## 4. âš ï¸ ê³ ì§ˆì  ë¦¬ìŠ¤í¬ ë° ê³¼ì œ (Chronic Issues)
(ë‹¨ë°œì„± ë²„ê·¸ê°€ ì•„ë‹Œ, ì„œë¹„ìŠ¤ ì „ì²´ ê¸°ê°„ ë™ì•ˆ ì§€ì†ì ìœ¼ë¡œ ì œê¸°ëœ ê·¼ë³¸ì  ë¬¸ì œ)
*   **Risk 1**: ...
*   **Risk 2**: ...

## 5. ğŸ”­ ë¯¸ë˜ ë¡œë“œë§µ ë° ì „ëµ ì œì–¸ (Strategic Roadmap)
(ì¶•ì ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, í–¥í›„ 3ë…„ ì´ìƒì„ ë°”ë¼ë³´ëŠ” ì¥ê¸°ì  ì „ëµ)
*   ...
"""
    try:
        model = genai.GenerativeModel('gemini-2.0-flash')
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(temperature=0.2)
        )
        return response.text
    except Exception as e:
        print(f"âŒ LLM ìƒì„± ì—ëŸ¬: {e}")
        return None

# ==============================================================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰
# ==============================================================================
def main():
    global vector_store, reranker
    
    genai.configure(api_key=GEMINI_API_KEY)
    
    print("ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘...", end=" ")
    embeddings = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL,
        model_kwargs={'device': device},
        encode_kwargs={'normalize_embeddings': True}
    )
    
    vector_store = Chroma(
        persist_directory=PERSIST_DIRECTORY,
        embedding_function=embeddings
    )
    
    try:
        reranker = CrossEncoder(RERANKER_MODEL_NAME, device=device, max_length=512)
    except:
        reranker = None
    print("ì™„ë£Œ")

    target_apps = get_target_apps(TARGET_GENRE)
    print(f"ğŸ“Š ëŒ€ìƒ ì•±: {len(target_apps)}ê°œ")

    for app in tqdm(target_apps, desc="App Loop"):
        app_name = app['a_name']
        app_id = app['a_idx']
        
        print(f"\nğŸ“± [{app_name}] L4 ì¢…í•© ë¶„ì„ ì‹œì‘")
        aggressive_gc()
        
        # 1. RAG ê²€ìƒ‰ (Total)
        context, years, _ = get_total_context(
            app_name, vector_store, reranker
        )
        
        if len(context) < MIN_CHUNKS_FOR_TOTAL:
            # print(f"  â­ï¸ ë°ì´í„° ë¶€ì¡± ({len(context)} chunks)")
            continue
            
        print(f"  ğŸ” {len(context)}ê°œ ì²­í¬ í™•ë³´ (ë¶„ì„ ê¸°ê°„: {min(years) if years else '?'} ~ {max(years) if years else '?'})")
        
        # 2. LLM ìƒì„±
        report_text = generate_l4_report(app_name, context, years)
        
        if report_text:
            # 3. DB ì €ì¥ (L4)
            if save_l4_report(app_id, report_text):
                print(f"    âœ… L4 ì¢…í•© ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ")
            else:
                print(f"    âŒ ì €ì¥ ì‹¤íŒ¨")
        else:
            print(f"    âš ï¸ ìƒì„± ì‹¤íŒ¨")
            
        time.sleep(1)

    print("\nğŸ‰ L4 ì¢…í•© ë¶„ì„ ì™„ë£Œ!")

if __name__ == "__main__":
    main()